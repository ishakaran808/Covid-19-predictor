{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ishakaran808/Covid-19-predictor/blob/main/Covid_19_predictor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UJ8O7heXQs53",
        "outputId": "b893acf3-dddd-423e-c3cb-fa85dcfddf11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.11%\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.82      0.86      0.84       307\n",
            "    positive       0.84      0.80      0.82       297\n",
            "\n",
            "    accuracy                           0.83       604\n",
            "   macro avg       0.83      0.83      0.83       604\n",
            "weighted avg       0.83      0.83      0.83       604\n",
            "\n",
            "Confusion Matrix:\n",
            "[[263  44]\n",
            " [ 58 239]]\n",
            "Cross-Validation Accuracy: 82.13%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('dataset.csv')\n",
        "\n",
        "# Drop unnecessary columns\n",
        "df = df.drop(columns=['Patient ID'])\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=['SARS-Cov-2 exam result'])\n",
        "y = df['SARS-Cov-2 exam result']\n",
        "\n",
        "# Handle missing values\n",
        "numeric_cols = X.select_dtypes(include=['number']).columns\n",
        "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
        "\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns\n",
        "X[categorical_cols] = X[categorical_cols].fillna(X[categorical_cols].mode().iloc[0])\n",
        "\n",
        "# Encode categorical features\n",
        "encoder = OneHotEncoder(sparse_output=False, drop='first')\n",
        "X_encoded = encoder.fit_transform(X[categorical_cols])\n",
        "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(categorical_cols))\n",
        "\n",
        "# Combine encoded columns with the original DataFrame\n",
        "X = X.drop(columns=categorical_cols)\n",
        "X = pd.concat([X, X_encoded_df], axis=1)\n",
        "\n",
        "# Replace 'not_detected' with NaN and fill missing values\n",
        "X.replace('not_detected', np.nan, inplace=True)\n",
        "X.fillna(X.mean(), inplace=True)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE()\n",
        "X_resampled, y_resampled = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "# Encode target labels\n",
        "label_encoder = LabelEncoder()\n",
        "y_resampled_encoded = label_encoder.fit_transform(y_resampled)\n",
        "\n",
        "# Feature selection using RandomForestClassifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_resampled, y_resampled)\n",
        "selector = SelectFromModel(rf, prefit=True, threshold='mean')\n",
        "X_selected = selector.transform(X_resampled)\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_selected, y_resampled_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Model Training with Hyperparameter Tuning\n",
        "xgb = XGBClassifier(eval_metric='logloss')\n",
        "\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20, 30],\n",
        "    'learning_rate': [0.01, 0.1, 1]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(xgb, param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_encoded = best_model.predict(X_test)\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# Decode y_test for evaluation\n",
        "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_decoded, y_pred))\n",
        "\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test_decoded, y_pred))\n",
        "\n",
        "# Cross-Validation Score\n",
        "cross_val_scores = cross_val_score(best_model, X_selected, y_resampled_encoded, cv=5)\n",
        "print(f'Cross-Validation Accuracy: {cross_val_scores.mean() * 100:.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "FAeEtsiBSJgJ",
        "outputId": "1f6b0881-5459-427a-b796-adb6b8b4cc92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 3888 candidates, totalling 19440 fits\n"
          ]
        }
      ],
      "source": [
        "# Adjust the SMOTE strategy\n",
        "from imblearn.combine import SMOTEENN\n",
        "\n",
        "smote_enn = SMOTEENN()\n",
        "X_resampled, y_resampled = smote_enn.fit_resample(X_scaled, y)\n",
        "\n",
        "# Re-encode the target variable\n",
        "y_resampled_encoded = label_encoder.fit_transform(y_resampled)\n",
        "\n",
        "# Split the data again\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled_encoded, test_size=0.2, random_state=42)\n",
        "\n",
        "# Updated Hyperparameter Tuning with a wider grid\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15, 20],\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'min_child_weight': [1, 5, 10],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'subsample': [0.8, 0.9, 1.0],\n",
        "    'scale_pos_weight': [1, 2, 5, 10]  # Important for handling class imbalance\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(XGBClassifier(eval_metric='logloss', random_state=42), param_grid, cv=5, scoring='f1_weighted', n_jobs=-1, verbose=2)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Predict on test data\n",
        "y_pred_encoded = best_model.predict(X_test)\n",
        "y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
        "\n",
        "# Decode y_test for evaluation\n",
        "y_test_decoded = label_encoder.inverse_transform(y_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test_decoded, y_pred)\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "print('Classification Report:')\n",
        "print(classification_report(y_test_decoded, y_pred))\n",
        "\n",
        "print('Confusion Matrix:')\n",
        "print(confusion_matrix(y_test_decoded, y_pred))\n",
        "\n",
        "# Cross-Validation Score\n",
        "cross_val_scores = cross_val_score(best_model, X_resampled, y_resampled_encoded, cv=5, scoring='f1_weighted')\n",
        "print(f'Cross-Validation Accuracy: {cross_val_scores.mean() * 100:.2f}%')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNWVjK6IaYVwzUB0LoSvRLv",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}